{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Основное задание:__\n",
    "Даны выборки для обучения и для тестирования. Задание заключается в том, чтобы попробовать разные способы валидации, проанализировать плюсы / минусы каждой и сделать выводы о том, какой способ валидации наиболее устойчивый в данной задаче. Метрика качества для оценки прогнозов - ROC-AUC, название целевой переменной - IsFraud. Рекомендуется использовать модели градиетного бустинга, реализация любая.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 394)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1:__ сделать Hold-Out валидацию с разбиением, размер которого будет адеквтаным, по вашему мнению; разбиение проводить по id-транзакции (TransactionID), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на тестовой выборке, оценить расхождение по сравнению с качеством на обучающей выборке и тестовой выборке.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(\n",
    "    data.drop([\"TransactionID\", \"isFraud\"], axis=1), train_size=0.666, shuffle=True, random_state=1,\n",
    ")\n",
    "y_train, y_test = train_test_split(\n",
    "    data[\"isFraud\"], train_size=0.666, shuffle=True, random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = 33300 rows, 378 cols\n",
      "x_test.shape = 16701 rows, 378 cols\n"
     ]
    }
   ],
   "source": [
    "numerical_features = x_train.select_dtypes(exclude=[\"object\"])\n",
    "numerical_features = numerical_features.columns.tolist()\n",
    "\n",
    "x_train = x_train[numerical_features]\n",
    "x_test = x_test[numerical_features]\n",
    "\n",
    "print(\"x_train.shape = {} rows, {} cols\".format(*x_train.shape))\n",
    "print(\"x_test.shape = {} rows, {} cols\".format(*x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.73568\tvalidation_1-auc:0.70872\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in -1 rounds.\n",
      "[1]\tvalidation_0-auc:0.81086\tvalidation_1-auc:0.78073\n",
      "[2]\tvalidation_0-auc:0.82044\tvalidation_1-auc:0.80011\n",
      "[3]\tvalidation_0-auc:0.84156\tvalidation_1-auc:0.81841\n",
      "[4]\tvalidation_0-auc:0.84694\tvalidation_1-auc:0.82648\n",
      "[5]\tvalidation_0-auc:0.86482\tvalidation_1-auc:0.84955\n",
      "[6]\tvalidation_0-auc:0.87516\tvalidation_1-auc:0.86231\n",
      "[7]\tvalidation_0-auc:0.88434\tvalidation_1-auc:0.86760\n",
      "[8]\tvalidation_0-auc:0.88724\tvalidation_1-auc:0.86714\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation_0-auc:0.88434\tvalidation_1-auc:0.86760\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=1,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(random_state=1)\n",
    "model.fit(x_train, y_train,  early_stopping_rounds=-1, eval_metric=\"auc\", eval_set=[(x_train, y_train), (x_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-score: 0.884, Test-score: 0.868\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, model.predict(x_train))\n",
    "test_score = roc_auc_score(y_test, model.predict(x_test))\n",
    "\n",
    "print(f\"Train-score: {round(train_score, 3)}, Test-score: {round(test_score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2:__ сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = 33330 rows, 378 cols\n",
      "x_valid.shape = 11112 rows, 378 cols\n",
      "x_test.shape = 5559 rows, 378 cols\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid  = train_test_split(\n",
    "    data.drop([\"TransactionID\", \"isFraud\"], axis=1), train_size=0.6666, shuffle=True, random_state=1,\n",
    ")\n",
    "y_train, y_valid = train_test_split(\n",
    "    data[\"isFraud\"], train_size=0.6666, shuffle=True, random_state=1,\n",
    ")\n",
    "\n",
    "x_train = x_train[numerical_features]\n",
    "x_valid = x_valid[numerical_features]\n",
    "\n",
    "x_valid, x_test = train_test_split(\n",
    "    x_valid, train_size=0.6666, shuffle=True, random_state=27\n",
    ")\n",
    "y_valid, y_test = train_test_split(\n",
    "    y_valid, train_size=0.6666, shuffle=True, random_state=27\n",
    ")\n",
    "\n",
    "print(\"x_train.shape = {} rows, {} cols\".format(*x_train.shape))\n",
    "print(\"x_valid.shape = {} rows, {} cols\".format(*x_valid.shape))\n",
    "print(\"x_test.shape = {} rows, {} cols\".format(*x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.75612\tvalidation_1-auc:0.74284\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in -1 rounds.\n",
      "[1]\tvalidation_0-auc:0.81938\tvalidation_1-auc:0.79439\n",
      "[2]\tvalidation_0-auc:0.82711\tvalidation_1-auc:0.80912\n",
      "[3]\tvalidation_0-auc:0.83601\tvalidation_1-auc:0.82251\n",
      "[4]\tvalidation_0-auc:0.86351\tvalidation_1-auc:0.85001\n",
      "[5]\tvalidation_0-auc:0.86910\tvalidation_1-auc:0.85534\n",
      "[6]\tvalidation_0-auc:0.87148\tvalidation_1-auc:0.85743\n",
      "[7]\tvalidation_0-auc:0.88332\tvalidation_1-auc:0.87088\n",
      "[8]\tvalidation_0-auc:0.89011\tvalidation_1-auc:0.87399\n",
      "[9]\tvalidation_0-auc:0.89549\tvalidation_1-auc:0.87783\n",
      "[10]\tvalidation_0-auc:0.89994\tvalidation_1-auc:0.88103\n",
      "[11]\tvalidation_0-auc:0.90292\tvalidation_1-auc:0.88312\n",
      "[12]\tvalidation_0-auc:0.90737\tvalidation_1-auc:0.88358\n",
      "[13]\tvalidation_0-auc:0.90813\tvalidation_1-auc:0.88483\n",
      "[14]\tvalidation_0-auc:0.90945\tvalidation_1-auc:0.88489\n",
      "[15]\tvalidation_0-auc:0.91476\tvalidation_1-auc:0.89088\n",
      "[16]\tvalidation_0-auc:0.91560\tvalidation_1-auc:0.89161\n",
      "[17]\tvalidation_0-auc:0.91889\tvalidation_1-auc:0.88968\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-auc:0.91560\tvalidation_1-auc:0.89161\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=0, num_parallel_tree=1, random_state=1,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(random_state=1,n_estimators=500)\n",
    "model.fit(x_train, y_train, \n",
    "          early_stopping_rounds=-1, eval_metric=\"auc\", eval_set=[(x_train, y_train), (x_valid, y_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-score: 0.916, Valid-score: 0.892, Test-score: 0.877\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, model.predict(x_train))\n",
    "valid_score = roc_auc_score(y_valid, model.predict(x_valid))\n",
    "test_score = roc_auc_score(y_test, model.predict(x_test))\n",
    "\n",
    "print(f\"Train-score: {round(train_score, 3)}, Valid-score: {round(valid_score, 3)}, Test-score: {round(test_score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3:__ построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на тестовом выборке относительно полученного доверительного интервала. Сделать выводы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8428974513645711, 0.9108542079421109)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(27)\n",
    "scores = create_bootstrap_metrics(y_test, model.predict(x_test), roc_auc_score)\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4:__ выполнить Adversarial Validation на основе данных из обучения / теста, подобрать объема из обучающей выборки, которые сильно похожи на объекты из тестовой выборки, и использовать их в качестве валидационного набора. Сделать выводы о полученных результатах.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pd.concat([\n",
    "    x_train, x_valid], axis=0)\n",
    "y_adv = np.hstack((np.zeros(x_train.shape[0]), np.ones(x_valid.shape[0])))\n",
    "assert x_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=25, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=25)\n",
    "model.fit(x_adv[numerical_features], y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(x_train[numerical_features])\n",
    "#roc_auc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]      102\n",
       "(0.1, 0.2]     3186\n",
       "(0.2, 0.3]    29018\n",
       "(0.3, 0.4]      951\n",
       "(0.4, 0.5]       63\n",
       "(0.5, 0.6]       10\n",
       "(0.6, 0.7]        0\n",
       "(0.7, 0.8]        0\n",
       "(0.8, 0.9]        0\n",
       "(0.9, 1.0]        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    y_pred[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 5:__ сделать KFold / StratifiedKFold валидацию (на ваше усмотрение), оценить получаемые качество и разброс по метрике качества. Сделать выводы об устойчивости кросс-валидации, сходимости оценки на кросс-валидации и отложенном наборе данных;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-results: 0.8515 +/- 0.023\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(\n",
    "    estimator=model,\n",
    "    X=data[numerical_features],\n",
    "    y=data[\"isFraud\"],\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(f\"CV-results: {round(np.mean(cv), 4)} +/- {round(np.std(cv), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(X: pd.DataFrame,\n",
    "                          y: pd.Series,\n",
    "                          estimator: object,\n",
    "                          metric: callable,\n",
    "                          cv_strategy):\n",
    "    estimators, fold_train_scores, fold_valid_scores = [], [], []\n",
    "    oof_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "        estimator.fit(x_train, y_train)\n",
    "        y_train_pred = estimator.predict(x_train)\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "\n",
    "        fold_train_scores.append(metric(y_train, y_train_pred))\n",
    "        fold_valid_scores.append(metric(y_valid, y_valid_pred))\n",
    "        oof_predictions[valid_idx] = y_valid_pred\n",
    "\n",
    "        msg = (\n",
    "            f\"Fold: {fold_number+1}, train-observations = {len(train_idx)}, \"\n",
    "            f\"valid-observations = {len(valid_idx)}\\n\"\n",
    "            f\"train-score = {round(fold_train_scores[fold_number], 4)}, \"\n",
    "            f\"valid-score = {round(fold_valid_scores[fold_number], 4)}\" \n",
    "        )\n",
    "        print(msg)\n",
    "        print(\"=\"*69)\n",
    "        estimators.append(estimator)\n",
    "\n",
    "    oof_score = metric(y, oof_predictions)\n",
    "    print(f\"CV-results train: {round(np.mean(fold_train_scores), 4)} +/- {round(np.std(fold_train_scores), 3)}\")\n",
    "    print(f\"CV-results valid: {round(np.mean(fold_valid_scores), 4)} +/- {round(np.std(fold_valid_scores), 3)}\")\n",
    "    print(f\"OOF-score = {round(oof_score, 4)}\")\n",
    "\n",
    "    return estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train-observations = 40000, valid-observations = 10001\n",
      "train-score = 0.919, valid-score = 0.82\n",
      "=====================================================================\n",
      "Fold: 2, train-observations = 40001, valid-observations = 10000\n",
      "train-score = 0.9168, valid-score = 0.8582\n",
      "=====================================================================\n",
      "Fold: 3, train-observations = 40001, valid-observations = 10000\n",
      "train-score = 0.9068, valid-score = 0.879\n",
      "=====================================================================\n",
      "Fold: 4, train-observations = 40001, valid-observations = 10000\n",
      "train-score = 0.909, valid-score = 0.8706\n",
      "=====================================================================\n",
      "Fold: 5, train-observations = 40001, valid-observations = 10000\n",
      "train-score = 0.8992, valid-score = 0.8761\n",
      "=====================================================================\n",
      "CV-results train: 0.9102 +/- 0.007\n",
      "CV-results valid: 0.8608 +/- 0.022\n",
      "OOF-score = 0.8593\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions = make_cross_validation(\n",
    "    data[numerical_features], data[\"isFraud\"], model, metric=roc_auc_score, cv_strategy=cv_strategy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Задание 6 * (опциональное):__ сделать Hold-Out валидацию по времени (TransactionDT), повторить процедуры из п.1 / п.2 (на ваш выбор). Построить доверительный интервал, сравнить качество на тестовой выборке с полученным доверительным интервалом. Сделать выводы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 7 ** (совсем опциональное):__ в данном наборе данных у нас есть ID-транзакции (TransactionID) и время транзакции (TransactionDT), но отсутствует ID-клиента, который совершал транзакции. Кажется, что в этой задаче валидация по клиенту работала бы хорошо. Предложить критерий, по которому можно выделить клиентов и сделать п.5, используя созданное определение клиента, используя валидацию по клиенту (GroupKFold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание на повторение:__\n",
    "Задание не обязательно к выполнению, но очень рекомендуется для понимания набора данных и получения гипотез для проведения валидации.   \n",
    "__Задание 1:__ Построить график распределения времени совершения транзакции для обучающей / тестовой выборки, сделать выводы о том, как разбиты данные и какие виды валидации могут подойти для данной задачи.   \n",
    "__Задание 2:__ построить scatter-plot зависимости суммы транзакции от времени совершения транзакции. Построить графики для обучающей выборки и для тестовой выборки, для обучающей выборки - построить как для целевой переменной = 0, так и для переменной = 1. Сделать выводы.   \n",
    "__Задание 3:__ построить распределение признака TransactionAmt в логарифмическом масштабе, сделать выводы о близости распредления к нормальному распределению. Построить распределение признака в логарифмическому масштабе для обучающей выборк и для тестовой выборки, сделать выводы.  \n",
    "__Задание 4:__ построить распределение признака целевой переменной в зависимости от значений категориальных признаков ProductCD, card4, card6. Сделать выводы.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
