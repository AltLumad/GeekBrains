{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        l = Y[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv(\"../Iris.csv\")\n",
    "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = pd.DataFrame(iris_data, columns=columns)\n",
    "x = normalize(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Species']\n",
    "y = pd.DataFrame(iris_data, columns=columns)\n",
    "y = y.values\n",
    "y = y.flatten()\n",
    "y = to_one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(count, input_count, output_count, internal_count):\n",
    "    np.random.seed(0)\n",
    "    result = [2*np.random.random((input_count, internal_count)) - 1]\n",
    "    for i in range(count-2):\n",
    "        result.append(2*np.random.random((internal_count, internal_count)) - 1)\n",
    "    result.append(2*np.random.random((internal_count, output_count)) - 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_layers(input_layer, weigths, use_relu_for_internal=False):\n",
    "    result = [input_layer]\n",
    "    if use_relu_for_internal:\n",
    "        for w in weigths[:-1]:\n",
    "            result.append(np.maximum(0,np.dot(result[-1], w)))\n",
    "        result.append(sigmoid(np.dot(result[-1], weigths[-1]))) \n",
    "        return result                      \n",
    "\n",
    "    for w in weigths:\n",
    "        result.append(sigmoid(np.dot(result[-1], w)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_weight(y_train, layers,weight, lerning_rate):\n",
    "    delta = (y_train - layers[-1]) * sigmoid_deriv(layers[-1])\n",
    "    error = delta\n",
    "    for i in range(len(layers)-2,-1,-1):\n",
    "        layer_error = delta.dot(weight[i].T)\n",
    "        weight[i] += layers[i].T.dot(delta) * lerning_rate\n",
    "        delta = layer_error * sigmoid_deriv(layers[i])\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вариант 1. Увеличение количества слоев__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нейронной сети 89.25%\n"
     ]
    }
   ],
   "source": [
    "weights = generate_weights(30,4,3,5)\n",
    "\n",
    "n = 0.01 \n",
    "errors = []\n",
    "\n",
    "for i in range(100000):\n",
    "    layers = generate_layers(X_train, weights)\n",
    "    error = correct_weight(y_train, layers, weights, n)\n",
    "    error = np.mean(np.abs(error))\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "\n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вариант 2. Увеличение количества нейронов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нейронной сети 99.65%\n"
     ]
    }
   ],
   "source": [
    "weights = generate_weights(2,4,3,200)\n",
    "\n",
    "n = 0.1 \n",
    "errors = []\n",
    "\n",
    "for i in range(100000):\n",
    "    layers = generate_layers(X_train, weights)\n",
    "    error = correct_weight(y_train, layers, weights, n)\n",
    "    error = np.mean(np.abs(error))\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "\n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вариант 3. Уменьшение скорости обучения__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нейронной сети 88.81%\n"
     ]
    }
   ],
   "source": [
    "weights = generate_weights(2,4,3,5)\n",
    "\n",
    "n = 0.000001 \n",
    "errors = []\n",
    "\n",
    "for i in range(100000):\n",
    "    layers = generate_layers(X_train, weights)\n",
    "    error = correct_weight(y_train, layers, weights, n)\n",
    "    error = np.mean(np.abs(error))\n",
    "    accuracy = (1 - error) * 100\n",
    "    \n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вариант 4. ReLu__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нейронной сети 94.66%\n"
     ]
    }
   ],
   "source": [
    "weights = generate_weights(2,4,3,5)\n",
    "\n",
    "n = 0.01 \n",
    "errors = []\n",
    "\n",
    "for i in range(100000):\n",
    "    layers = generate_layers(X_train, weights, True)\n",
    "    error = correct_weight(y_train, layers, weights, n)\n",
    "    error = np.mean(np.abs(error))\n",
    "    accuracy = (1 - error) * 100\n",
    "    \n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выводы__\n",
    "\n",
    "1. Бездумное увеличение слоев не всегда ведёт к повышению точности.   \n",
    "2. Увеличение количества нейронов повышает точность\n",
    "3. Если сильно уменьшить скорость обучения, нейронная сеть может не успеть обучится за отведенное количество итераций.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
