{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тему плохо понял, в этой связи, 1 и 6 не сделал, а в остальных заданиях не уверен. На выходных,  доделаю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1__. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2__. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    При iterations=100000 и alpha=0.315   \n",
    "    err=0.08042813845347312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3__. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    y_predicted = 1 / (1 + np.exp(np.dot(W,X)))\n",
    "    return y_predicted    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4__. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X):\n",
    "    y_predicted = np.dot(W,X)\n",
    "    for i in range(y_predicted.shape[0]):\n",
    "        y_predicted[i] = 0 if y_predicted[i] < 0 else 1\n",
    "    return y_predicted   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5__. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2,  1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)\n",
    "\n",
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res\n",
    "\n",
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])\n",
    "\n",
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    err = np.sum(err)\n",
    "    return err\n",
    "\n",
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res\n",
    "\n",
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "    return W\n",
    "\n",
    "W = eval_model(X_st, y, iterations=16500, alpha=0.00935)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\t 0.8\n",
      "error matrix:\t\n",
      "\t\tTP=4 FP=1\n",
      "\t\tFN=1 TN=4\n",
      "precision:\t 0.8\n",
      "recall:\t\t 0.8\n",
      "F-score:\t 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "y_pred = calc_pred(W,X)\n",
    "def accuracy(y, y_pred):\n",
    "    res = 0\n",
    "    for i in range(len(y)):\n",
    "        res += 1 if y[i] == y_pred[i] else 0\n",
    "    return res/len(y)\n",
    "\n",
    "def error_matrix(y, y_pred):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i] and y[i] == 1: TP += 1\n",
    "        elif y[i] != y_pred[i] and y_pred[i] == 1: FP += 1\n",
    "        elif y[i] != y_pred[i] and y[i] == 1: FN += 1\n",
    "        elif y[i] == y_pred[i] and y[i] == 0: TN += 1\n",
    "        else: raise Exception(f'y = {y[i]}\\t y_pred={y_pred[i]}')\n",
    "    return TP,FP,FN,TN\n",
    "\n",
    "\n",
    "print('accuracy:\\t', accuracy(y,y_pred))\n",
    "TP,FP,FN,TN = error_matrix(y, y_pred)\n",
    "print('error matrix:\\t',f'TP={TP} FP={FP}',f'FN={FN} TN={TN}' , sep='\\n\\t\\t')\n",
    "print('precision:\\t',TP/(TP+FP))\n",
    "print('recall:\\t\\t',TP/(TP+FN))\n",
    "print('F-score:\\t', 2*(TP/(TP+FP)*TP/(TP+FN))/(TP/(TP+FP) +TP/(TP+FN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6__. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
